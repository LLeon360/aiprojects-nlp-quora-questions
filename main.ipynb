{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml6mBuOn0S99"
      },
      "source": [
        "# Starter code for the skeleton notebook\n",
        "\n",
        "If you are running this notebook on **Google Colab**, make sure you are using a GPU runtime.\n",
        "\n",
        "This notebook mounts drive to load embeddings and data you can find them on the kaggle link on https://www.kaggle.com/competitions/quora-insincere-questions-classification/data\n",
        "\n",
        "When running Colab, it automatically grabs scripts from\n",
        "https://github.com/LLeon360/aiprojects-nlp-quora-questions\n",
        "\n",
        "Checkout [data/starting_dataset.py](data/EmbeddingsDataset.py) for the dataset processing code. \\\n",
        "Checkout [networks/StartingNetwork.py](networks/LSTMEncoder.py) for the neural network code. \\\n",
        "Checkout [train_functions/starting_train.py](train_functions/lstm_train.py) for the training code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbelhIW90YmW"
      },
      "source": [
        "### Mount Drive (Google Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "othw1k2q0YVZ",
        "outputId": "e32b002a-ffa2-4058-e164-17d7b6ea384a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJofTGNg0S-C"
      },
      "source": [
        "### Grab scripts from GitHub Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tSIA5ej0S-D",
        "outputId": "35b45657-a3d0-417f-9b6f-83fc835101fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'scripts'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 239 (delta 15), reused 26 (delta 10), pack-reused 203\u001b[K\n",
            "Receiving objects: 100% (239/239), 112.80 KiB | 3.89 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n",
            "renamed 'scripts/acmprojects.yml' -> './acmprojects.yml'\n",
            "renamed 'scripts/constants.py' -> './constants.py'\n",
            "renamed 'scripts/data' -> './data'\n",
            "renamed 'scripts/kaggle.json' -> './kaggle.json'\n",
            "renamed 'scripts/main.ipynb' -> './main.ipynb'\n",
            "renamed 'scripts/networks' -> './networks'\n",
            "renamed 'scripts/README.md' -> './README.md'\n",
            "renamed 'scripts/train_functions' -> './train_functions'\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/LLeon360/aiprojects-nlp-quora-questions scripts\n",
        "!mv  -v scripts/* ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPRXgOh40S-E"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7kVI2V50S-G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import constants\n",
        "\n",
        "from data.StartingDataset import StartingDataset\n",
        "from networks.StartingNetwork import StartingNetwork\n",
        "from train_functions.lstm_train import lstm_train\n",
        "\n",
        "from data.EmbeddingDataset import EmbeddingDataset\n",
        "from networks.LSTMEncoder import LSTMEncoder\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import random_split, WeightedRandomSampler, BatchSampler\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bnBg2Q90S-H"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mUo6imf0S-I"
      },
      "outputs": [],
      "source": [
        "# EPOCHS = 100\n",
        "# BATCH_SIZE = 32\n",
        "# N_EVAL = 100\n",
        "# VAL_SPLIT = 0.1\n",
        "\n",
        "from constants import EPOCHS, BATCH_SIZE, N_EVAL, VAL_SPLIT\n",
        "VAL_SPLIT = 0.05\n",
        "EPOCHS = 1;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g_N4q0y0S-J"
      },
      "source": [
        "### GPU Support\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ-B2B3S0S-J"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvrylDtM0S-K"
      },
      "source": [
        "### Define hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLg-hJ5y0S-K"
      },
      "outputs": [],
      "source": [
        "hyperparameters = {\"epochs\": EPOCHS, \"batch_size\": BATCH_SIZE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfusRszp0S-L"
      },
      "source": [
        "### Load Embeddings\n",
        "\n",
        "You need to have the embeddings installed and stored in the matching filepath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOxtRRFR0S-L"
      },
      "outputs": [],
      "source": [
        "full_content = pd.read_csv('/content/drive/MyDrive/AI/quora_nlp/glove.6B.300d.txt', delim_whitespace = True, quoting=csv.QUOTE_NONE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-lqQCxA0S-M"
      },
      "outputs": [],
      "source": [
        "# full_content.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KU4J2Otu0S-M"
      },
      "outputs": [],
      "source": [
        "#separate words and embeddings\n",
        "i_word = full_content.iloc[:,0]\n",
        "i_embeddings = full_content.iloc[:,1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3BDb2320S-N"
      },
      "outputs": [],
      "source": [
        "# from series to numpy\n",
        "vocab_npa = np.array(i_word)\n",
        "embs_npa = np.array(i_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGPOfZR50S-N"
      },
      "outputs": [],
      "source": [
        "# prepend special padding token and unknown token\n",
        "vocab_npa = np.insert(vocab_npa, 0, '<pad>')\n",
        "vocab_npa = np.insert(vocab_npa, 1, '<unk>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49ppjIzE0S-O"
      },
      "outputs": [],
      "source": [
        "pad_emb_npa = np.zeros((1, embs_npa.shape[1]))\n",
        "unk_emb_npa = np.mean(embs_npa, axis=0, keepdims=True)\n",
        "\n",
        "#insert embeddings for pad and unk tokens to embs_npa.\n",
        "embs_npa = np.vstack((pad_emb_npa,unk_emb_npa,embs_npa))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT9DFtYN0S-O",
        "outputId": "7b207f5b-dd51-495b-b8c2-b4227fc12afa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400001,)\n",
            "(400001, 300)\n"
          ]
        }
      ],
      "source": [
        "print(vocab_npa.shape)\n",
        "print(embs_npa.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY6y9ONc0S-P"
      },
      "source": [
        "### Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJrA3NSq0S-P"
      },
      "outputs": [],
      "source": [
        "entire_df = pd.read_csv(\"/content/drive/MyDrive/AI/quora_nlp/train.csv\")\n",
        "# entire_df = pd.read_csv(\"train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YE04ZpE4kPh"
      },
      "outputs": [],
      "source": [
        "train_df, val_df = train_test_split(entire_df, test_size=VAL_SPLIT)\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/AI/quora_nlp/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6mSe7SdyImZ",
        "outputId": "8b616821-2e94-49c5-e4b6-30e73c4065fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1240815\n",
            "65307\n"
          ]
        }
      ],
      "source": [
        "print(len(train_df))\n",
        "print(len(val_df))\n",
        "# print(len(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Class imbalance"
      ],
      "metadata": {
        "id": "iO5C-nETDo6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pull out negative and positives\n",
        "negative_df = entire_df[entire_df[\"target\"] == 0]\n",
        "positive_df = entire_df[entire_df[\"target\"] == 1]\n",
        "print(len(negative_df))\n",
        "print(len(positive_df))\n",
        "print(len(negative_df) / len(positive_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TmTH7bzDq3B",
        "outputId": "29db274a-9a55-48f6-9cd6-09eeb0e1a14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1225312\n",
            "80810\n",
            "15.16287588169781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Weighted Sampler\n",
        "\n",
        "There is a pretty significant class imbalance, mostly negative cases so use weighted sampler to train the model on a balance of both"
      ],
      "metadata": {
        "id": "dMG_rPC7Cf0r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XG8rtkQcBdud"
      },
      "outputs": [],
      "source": [
        "weights = np.ones(len(train_df))\n",
        "weights[train_df.target==1] *= 15\n",
        "weights /= (len(train_df)) # Pytorch docs says probabilities don't have to add up to 1, but when you don't do this it doesn't work :(\n",
        "\n",
        "sampler = WeightedRandomSampler(weights=weights, num_samples=len(train_df), replacement=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1UxRij10S-P"
      },
      "source": [
        "### Initialize datasets and model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fsa2XlXZ0S-Q"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    #model configurations\n",
        "    'batch_size':32,\n",
        "    'max_seq_length':100,\n",
        "    'lr':1e-3,\n",
        "    'label_count':2,\n",
        "    'dropout_prob':2e-1,\n",
        "    'hidden_size':256,\n",
        "    'lstm_unit_cnt':2,\n",
        "\n",
        "    #embeddings configurations\n",
        "    'pretrained_embeddings':embs_npa,\n",
        "    'freeze_embeddings':True,\n",
        "    'vocab':vocab_npa,\n",
        "    'pad_token':'<pad>',\n",
        "    'unk_token':'<unk>',\n",
        "\n",
        "    #data\n",
        "    'train_df': train_df,\n",
        "    'val_df': val_df,\n",
        "    'test_df': test_df,\n",
        "\n",
        "    'device': device,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ9Hr29-0S-Q"
      },
      "outputs": [],
      "source": [
        "# starting fc network, ignore for embeddings and lstm\n",
        "# data_path = \"mini_train.csv\"\n",
        "\n",
        "# train_dataset = StartingDataset(data_path)\n",
        "# #val split\n",
        "# generator1 = torch.Generator().manual_seed(42)\n",
        "# train_dataset, val_dataset = random_split(train_dataset, [1-VAL_SPLIT, VAL_SPLIT], generator = generator1)\n",
        "# model = StartingNetwork()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgXh4I270S-R"
      },
      "outputs": [],
      "source": [
        "# print(len(train_dataset))\n",
        "# print(len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rTZGTeY0S-R",
        "outputId": "49f494dd-a472-436c-afc4-8e80f28ef848"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMEncoder(\n",
              "  (embedding): Embedding(400001, 300)\n",
              "  (lstm): LSTM(300, 256, num_layers=2, batch_first=True)\n",
              "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model = LSTMEncoder(config)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KZkRSiI0S-S"
      },
      "outputs": [],
      "source": [
        "train_dataset = EmbeddingDataset(\n",
        "    df = config['train_df'],\n",
        "    vocab = config['vocab'],\n",
        "    max_seq_length = config['max_seq_length'],\n",
        "    pad_token = config['pad_token'],\n",
        "    unk_token = config['unk_token']\n",
        ")\n",
        "\n",
        "val_dataset = EmbeddingDataset(\n",
        "    df = config['val_df'],\n",
        "    vocab = config['vocab'],\n",
        "    max_seq_length = config['max_seq_length'],\n",
        "    pad_token = config['pad_token'],\n",
        "    unk_token = config['unk_token']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Sampler"
      ],
      "metadata": {
        "id": "HAllsIF-B7ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_sampler=BatchSampler(sampler,32, True)\n",
        ")"
      ],
      "metadata": {
        "id": "vDm2ZggACEEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOs3mUvE0S-U"
      },
      "source": [
        "### Train model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5n6lVMs0S-U"
      },
      "outputs": [],
      "source": [
        "lstm_train(\n",
        "    train_dataset=train_dataset,\n",
        "    val_dataset=val_dataset,\n",
        "    train_sampler = sampler,\n",
        "    model=model,\n",
        "    hyperparameters=hyperparameters,\n",
        "    n_eval=N_EVAL,\n",
        "    device=device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "T0mFCPcEPp6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"entire_model.pt\"\n",
        "\n",
        "# Save\n",
        "torch.save(model, PATH)"
      ],
      "metadata": {
        "id": "gc6s0ABSyAkF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}